{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classification_NLP@SAMSUNG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOackDV+dcL4uMPjMekjFqY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julichitai/learning_NN/blob/NLP/text_classification_NLP_SAMSUNG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaqG73vNuDgh"
      },
      "source": [
        "## Тематическая классификация длинных текстов - TFIDF и LogReg¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD_VxM7gt450",
        "outputId": "a15d035a-3e55-4631-a09f-fa5be926e3ac"
      },
      "source": [
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "import sys; sys.path.append('./stepik-dl-nlp')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stepik-dl-nlp'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 289 (delta 10), reused 14 (delta 6), pack-reused 266\u001b[K\n",
            "Receiving objects: 100% (289/289), 42.27 MiB | 24.86 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 1)) (0.22.2.post1)\n",
            "Collecting spacy-udpipe\n",
            "  Downloading https://files.pythonhosted.org/packages/16/60/2a985e25f6a398655f018e5e43d16ba3dbd65f0d4d6ae22add90578669a5/spacy_udpipe-0.3.2-py3-none-any.whl\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 4)) (1.7.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 5)) (3.2.2)\n",
            "Collecting ipymarkup\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/9b/bf54c98d50735a4a7c84c71e92c5361730c878ebfe903d2c2d196ef66055/ipymarkup-0.9.0-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 7)) (4.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 9)) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 10)) (4.41.1)\n",
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 23.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 12)) (0.11.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 13)) (4.10.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 14)) (5.5.0)\n",
            "Collecting pyconll\n",
            "  Downloading https://files.pythonhosted.org/packages/39/6f/86bd5d0eaa6821ba9193bbed16b660ea6f342fe63ec2e4fa2c61377bb44b/pyconll-2.3.3-py3-none-any.whl\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.3MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Collecting livelossplot==0.5.3\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/08/1884157a3de72d41fa97cacacafaa49abf00eba53cb7e08615b2b65b4a9d/livelossplot-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (1.19.4)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.2.4)\n",
            "Collecting ufal.udpipe>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 49.5MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2->-r stepik-dl-nlp/requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (0.10.0)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r stepik-dl-nlp/requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome->-r stepik-dl-nlp/requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (51.0.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.8.0)\n",
            "Requirement already satisfied: requests>=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r stepik-dl-nlp/requirements.txt (line 16)) (4.0.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r stepik-dl-nlp/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (2.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from intervaltree>=3->ipymarkup->-r stepik-dl-nlp/requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.7.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (20.0.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (7.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (2.11.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (20.8)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (3.13)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot==0.5.3->-r stepik-dl-nlp/requirements.txt (line 18)) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.4.0)\n",
            "Building wheels for collected packages: wget, ufal.udpipe, intervaltree\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=7554083728a8e0fe2e51b5b4d02d2e58f5ffb873771addc64581514841ff7a6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp36-cp36m-linux_x86_64.whl size=5625174 sha256=7420723c427edea6b8f061c4fde42a175164849fa2e592dd87aa54fe9aaaeb9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26102 sha256=ba600fc69ac47d804e7ad770b2ba61f1b2c3d8e177bdefefab00304fb6ddee52\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built wget ufal.udpipe intervaltree\n",
            "Installing collected packages: ufal.udpipe, spacy-udpipe, dawg-python, pymorphy2-dicts-ru, pymorphy2, intervaltree, ipymarkup, youtokentome, pyconll, gensim, wget, livelossplot\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed dawg-python-0.7.2 gensim-3.8.1 intervaltree-3.1.0 ipymarkup-0.9.0 livelossplot-0.5.3 pyconll-2.3.3 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 spacy-udpipe-0.3.2 ufal.udpipe-1.2.0.3 wget-3.2 youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP3sA5lxsKDB"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import dlnlputils\n",
        "\n",
        "# from dlnlputils.data import tokenize_text_simple_regex, tokenize_corpus, build_vocabulary, vectorize_texts, SparseFeaturesDataset, TOKEN_RE\n",
        "# from dlnlputils.pipeline import train_eval_loop, init_random_seed, predict_with_model\n",
        "\n",
        "from dlnlputils.pipeline import init_random_seed\n",
        "from dlnlputils.data import TOKEN_RE\n",
        "\n",
        "\n",
        "init_random_seed()"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqRICoXPbfua"
      },
      "source": [
        "def copy_data_to_device(data, device):\n",
        "    if torch.is_tensor(data):\n",
        "        return data.to(device)\n",
        "    elif isinstance(data, (list, tuple)):\n",
        "        return [copy_data_to_device(elem, device) for elem in data]\n",
        "    raise ValueError('Недопустимый тип данных {}'.format(type(data)))"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILAtvxItxMHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b50f9e1-a6ca-4b8d-b8b3-530b80ee2c89"
      },
      "source": [
        "TOKEN_RE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "re.compile(r'[\\w\\d]+', re.UNICODE)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12zAUJphwDHa"
      },
      "source": [
        "def tokenize_text_simple_regex(txt, min_token_size=4):\n",
        "    txt = txt.lower()\n",
        "    all_tokens = TOKEN_RE.findall(txt)\n",
        "    return [token for token in all_tokens if len(token) >= min_token_size]\n",
        "\n",
        "\n",
        "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
        "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]\n",
        "\n",
        "\n",
        "def build_vocabulary(tokenized_texts, max_size=1000000, max_doc_freq=0.8, min_count=5, pad_word=None, is_lemm=False, is_stem=False):\n",
        "    word_counts = collections.defaultdict(int)\n",
        "    doc_n = 0\n",
        "\n",
        "    # посчитать количество документов, в которых употребляется каждое слово\n",
        "    # а также общее количество документов\n",
        "    for txt in tqdm(tokenized_texts):\n",
        "        if is_stem:\n",
        "            # nltk.stemmer.PorterStemmer()\n",
        "            sno = nltk.stem.SnowballStemmer('english')\n",
        "            stem_txt = [sno.stem(i) for i in txt]\n",
        "            txt = stem_txt\n",
        "        if is_lemm:\n",
        "            lemma = nltk.wordnet.WordNetLemmatizer()\n",
        "            lemm_txt = [lemma.lemmatize(i) for i in txt]\n",
        "            txt = lemm_txt\n",
        "\n",
        "        doc_n += 1\n",
        "        unique_text_tokens = set(txt)\n",
        "        for token in unique_text_tokens:\n",
        "            word_counts[token] += 1\n",
        "\n",
        "    # убрать слишком редкие и слишком частые слова\n",
        "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
        "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
        "\n",
        "    # отсортировать слова по убыванию частоты\n",
        "    sorted_word_counts = sorted(word_counts.items(),\n",
        "                                reverse=True,\n",
        "                                key=lambda pair: pair[1])\n",
        "\n",
        "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
        "    if pad_word is not None:\n",
        "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
        "\n",
        "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
        "    if len(word_counts) > max_size:\n",
        "        sorted_word_counts = sorted_word_counts[:max_size]\n",
        "\n",
        "    # нумеруем слова\n",
        "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
        "\n",
        "    # нормируем частоты слов\n",
        "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
        "\n",
        "    return word2id, word2freq\n",
        "\n",
        "\n",
        "def vectorize_texts(tokenized_texts, word2id, word2freq, mode='tfidf', scale=True):\n",
        "    assert mode in {'tfidf', 'idf', 'tf', 'bin', 'pmi'}\n",
        "\n",
        "    # считаем количество употреблений каждого слова в каждом документе\n",
        "    result = scipy.sparse.dok_matrix((len(tokenized_texts), len(word2id)), dtype='float32')\n",
        "    for text_i, text in tqdm(enumerate(tokenized_texts)):\n",
        "        for token in text:\n",
        "            if token in word2id:\n",
        "                result[text_i, word2id[token]] += 1\n",
        "\n",
        "    # получаем бинарные вектора \"встречается или нет\"\n",
        "    if mode == 'bin':\n",
        "        result = (result > 0).astype('float32')\n",
        "\n",
        "    # получаем вектора относительных частот слова в документе\n",
        "    elif mode == 'tf':\n",
        "        result = result.tocsr()\n",
        "        result = result.multiply(1 / result.sum(1))\n",
        "\n",
        "    # полностью убираем информацию о количестве употреблений слова в данном документе,\n",
        "    # но оставляем информацию о частотности слова в корпусе в целом\n",
        "    elif mode == 'idf':\n",
        "        result = (result > 0).astype('float32').multiply(1 / word2freq)\n",
        "\n",
        "    # учитываем всю информацию, которая у нас есть:\n",
        "    # частоту слова в документе и частоту слова в корпусе\n",
        "    elif mode == 'tfidf':\n",
        "        result = result.tocsr()\n",
        "        result = result.multiply(1 / result.sum(1))  # разделить каждую строку на её длину\n",
        "        result = result.multiply(1 / word2freq)  # разделить каждый столбец на вес слова\n",
        "\n",
        "    # точечной взаимной информации (PMI)\n",
        "    elif mode == 'pmi':\n",
        "      sum_of_sizes_of_docs = np.array(result.sum())\n",
        "      sizes_of_every_doc = np.array(result.sum(1))\n",
        "      count_word_in_docs = np.array(result.sum(0))\n",
        "      result = result.multiply((sum_of_sizes_of_docs**2)/((sizes_of_every_doc**2) * count_word_in_docs))\n",
        "      result.data = np.log(result.data)\n",
        "\n",
        "    if scale:\n",
        "        result = result.tocsc()\n",
        "        result -= result.min()\n",
        "        result /= (result.max() + 1e-6)\n",
        "\n",
        "    return result.tocsr()"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMpJg6OnwSyb"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SparseFeaturesDataset(Dataset):\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        cur_features = torch.from_numpy(self.features[idx].toarray()[0]).float()\n",
        "        cur_label = torch.from_numpy(np.asarray(self.targets[idx])).long()\n",
        "        return cur_features, cur_label"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7JllmaFwoEY"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import datetime \n",
        "import copy\n",
        "\n",
        "\n",
        "def train_eval_loop(model, train_dataset, val_dataset, criterion,\n",
        "                    lr=1e-4, epoch_n=10, batch_size=32,\n",
        "                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n",
        "                    max_batches_per_epoch_train=10000,\n",
        "                    max_batches_per_epoch_val=1000,\n",
        "                    data_loader_ctor=DataLoader,\n",
        "                    optimizer_ctor=None,\n",
        "                    lr_scheduler_ctor=None,\n",
        "                    shuffle_train=True,\n",
        "                    dataloader_workers_n=0):\n",
        "    \"\"\"\n",
        "    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n",
        "    :param model: torch.nn.Module - обучаемая модель\n",
        "    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n",
        "    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n",
        "    :param criterion: функция потерь для настройки модели\n",
        "    :param lr: скорость обучения\n",
        "    :param epoch_n: максимальное количество эпох\n",
        "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
        "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
        "    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n",
        "        отсутствие улучшения модели, чтобы обучение продолжалось.\n",
        "    :param l2_reg_alpha: коэффициент L2-регуляризации\n",
        "    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n",
        "    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n",
        "    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n",
        "        (по умолчанию torch.utils.data.DataLoader)\n",
        "    :return: кортеж из двух элементов:\n",
        "        - среднее значение функции потерь на валидации на лучшей эпохе\n",
        "        - лучшая модель\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    device = torch.device(device)\n",
        "    model.to(device)\n",
        "\n",
        "    if optimizer_ctor is None:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n",
        "    else:\n",
        "        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n",
        "\n",
        "    if lr_scheduler_ctor is not None:\n",
        "        lr_scheduler = lr_scheduler_ctor(optimizer)\n",
        "    else:\n",
        "        lr_scheduler = None\n",
        "\n",
        "    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n",
        "                                        num_workers=dataloader_workers_n)\n",
        "    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                                      num_workers=dataloader_workers_n)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_epoch_i = 0\n",
        "    best_model = copy.deepcopy(model)\n",
        "\n",
        "    for epoch_i in range(epoch_n):\n",
        "        try:\n",
        "            epoch_start = datetime.datetime.now()\n",
        "            print('Эпоха {}'.format(epoch_i))\n",
        "\n",
        "            model.train()\n",
        "            mean_train_loss = 0\n",
        "            train_batches_n = 0\n",
        "            for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
        "                if batch_i > max_batches_per_epoch_train:\n",
        "                    break\n",
        "\n",
        "                batch_x = copy_data_to_device(batch_x, device)\n",
        "                batch_y = copy_data_to_device(batch_y, device)\n",
        "\n",
        "                pred = model(batch_x)\n",
        "                loss = criterion(pred, batch_y)\n",
        "\n",
        "                model.zero_grad()\n",
        "                loss.backward()\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                mean_train_loss += float(loss)\n",
        "                train_batches_n += 1\n",
        "\n",
        "            mean_train_loss /= train_batches_n\n",
        "            print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n",
        "                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\n",
        "            print('Среднее значение функции потерь на обучении', mean_train_loss)\n",
        "\n",
        "\n",
        "\n",
        "            model.eval()\n",
        "            mean_val_loss = 0\n",
        "            val_batches_n = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
        "                    if batch_i > max_batches_per_epoch_val:\n",
        "                        break\n",
        "\n",
        "                    batch_x = copy_data_to_device(batch_x, device)\n",
        "                    batch_y = copy_data_to_device(batch_y, device)\n",
        "\n",
        "                    pred = model(batch_x)\n",
        "                    loss = criterion(pred, batch_y)\n",
        "\n",
        "                    mean_val_loss += float(loss)\n",
        "                    val_batches_n += 1\n",
        "\n",
        "            mean_val_loss /= val_batches_n\n",
        "            print('Среднее значение функции потерь на валидации', mean_val_loss)\n",
        "\n",
        "            if mean_val_loss < best_val_loss:\n",
        "                best_epoch_i = epoch_i\n",
        "                best_val_loss = mean_val_loss\n",
        "                best_model = copy.deepcopy(model)\n",
        "                print('Новая лучшая модель!')\n",
        "            elif epoch_i - best_epoch_i > early_stopping_patience:\n",
        "                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n",
        "                    early_stopping_patience))\n",
        "                break\n",
        "\n",
        "            if lr_scheduler is not None:\n",
        "                lr_scheduler.step(mean_val_loss)\n",
        "\n",
        "            print()\n",
        "        except KeyboardInterrupt:\n",
        "            print('Досрочно остановлено пользователем')\n",
        "            break\n",
        "        except Exception as ex:\n",
        "            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n",
        "            break\n",
        "\n",
        "    return best_val_loss, best_model"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPgG_jivwtY1"
      },
      "source": [
        "def predict_with_model(model, dataset, device=None, batch_size=32, num_workers=0, return_labels=False):\n",
        "    \"\"\"\n",
        "    :param model: torch.nn.Module - обученная модель\n",
        "    :param dataset: torch.utils.data.Dataset - данные для применения модели\n",
        "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
        "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
        "    :return: numpy.array размерности len(dataset) x *\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    results_by_batch = []\n",
        "\n",
        "    device = torch.device(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        import tqdm\n",
        "        for batch_x, batch_y in tqdm.tqdm(dataloader, total=len(dataset)/batch_size):\n",
        "            batch_x = copy_data_to_device(batch_x, device)\n",
        "\n",
        "            if return_labels:\n",
        "                labels.append(batch_y.numpy())\n",
        "\n",
        "            batch_pred = model(batch_x)\n",
        "            results_by_batch.append(batch_pred.detach().cpu().numpy())\n",
        "\n",
        "    if return_labels:\n",
        "        return np.concatenate(results_by_batch, 0), np.concatenate(labels, 0)\n",
        "    else:\n",
        "        return np.concatenate(results_by_batch, 0)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-S-_aJZuHR7"
      },
      "source": [
        "### Предобработка текстов и подготовка признаков\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1h7e4D7sOp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f5ae74-6aec-4915-ddc2-1d7e0d20f9dd"
      },
      "source": [
        "train_data = fetch_20newsgroups(subset='train')\n",
        "test_data = fetch_20newsgroups(subset='test')\n",
        "\n",
        "print('Количество обучающих текстов', len(train_data['data']))\n",
        "print('Количество тестовых текстов', len(test_data['data']))\n",
        "\n",
        "print()\n",
        "print(train_data['data'][0].strip())\n",
        "print()\n",
        "print('Имена целевых переменных', train_data['target_names'])\n",
        "print('Метка', train_data['target'][0])"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество обучающих текстов 11314\n",
            "Количество тестовых текстов 7532\n",
            "\n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "Имена целевых переменных ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Метка 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWjg6HIMuJxf"
      },
      "source": [
        "#### Подготовка признаков\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwl2A9tcw8IB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac4f0e2-79fe-4435-a718-515753ad0d56"
      },
      "source": [
        "train_tokenized = tokenize_corpus(train_data['data'])\n",
        "test_tokenized = tokenize_corpus(test_data['data'])\n",
        "\n",
        "print(' '.join(train_tokenized[0]))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from lerxst where thing subject what this nntp posting host rac3 organization university maryland college park lines wondering anyone there could enlighten this other door sports looked from late early called bricklin doors were really small addition front bumper separate from rest body this know anyone tellme model name engine specs years production where this made history whatever info have this funky looking please mail thanks brought your neighborhood lerxst\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxF6P34Y-inZ",
        "outputId": "5198b7da-eb9b-4fc4-c7ec-93434fb9d55d"
      },
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "MAX_DF = 0.8\n",
        "MIN_COUNT = 5\n",
        "vocabulary, word_doc_freq = build_vocabulary(train_tokenized,\n",
        "                                             max_doc_freq=MAX_DF,\n",
        "                                             min_count=MIN_COUNT,\n",
        "                                             is_lemm=False,\n",
        "                                             is_stem=False)\n",
        "UNIQUE_WORDS_N = len(vocabulary)\n",
        "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
        "print(list(vocabulary.items())[:10])"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11314/11314 [00:00<00:00, 31947.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Количество уникальных токенов 21628\n",
            "[('that', 0), ('this', 1), ('have', 2), ('with', 3), ('writes', 4), ('article', 5), ('posting', 6), ('host', 7), ('nntp', 8), ('there', 9)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLrDfBExjfrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79751f40-ab3c-46d4-d187-6e50870a471c"
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "CH9K2kjs-xOm",
        "outputId": "6870ef3b-62fc-4a8e-db8b-0e99a701d986"
      },
      "source": [
        "plt.hist(word_doc_freq, bins=20)\n",
        "plt.title('Распределение относительных частот слов')\n",
        "plt.yscale('log');"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZWFEzZpBzBh",
        "outputId": "26ec8f54-f9ea-4f78-c4a3-6b54857025f7"
      },
      "source": [
        "VECTORIZATION_MODE = 'pmi'\n",
        "train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
        "test_vectors = vectorize_texts(test_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
        "\n",
        "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
        "print('Размерность матрицы признаков тестовой выборки', test_vectors.shape)\n",
        "print()\n",
        "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
        "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
        "print()\n",
        "print('Количество ненулевых элементов в тестовой выборке', test_vectors.nnz)\n",
        "print('Процент заполненности матрицы признаков {:.2f}%'.format(test_vectors.nnz * 100 / (test_vectors.shape[0] * test_vectors.shape[1])))"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11314it [00:41, 273.23it/s]\n",
            "7532it [00:26, 285.79it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:95: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Размерность матрицы признаков обучающей выборки (11314, 21628)\n",
            "Размерность матрицы признаков тестовой выборки (7532, 21628)\n",
            "\n",
            "Количество ненулевых элементов в обучающей выборке 1126792\n",
            "Процент заполненности матрицы признаков 0.46%\n",
            "\n",
            "Количество ненулевых элементов в тестовой выборке 721529\n",
            "Процент заполненности матрицы признаков 0.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "5SGTuiA9OWCP",
        "outputId": "ad0cfaed-0ecd-4114-d87a-de58caef3219"
      },
      "source": [
        "plt.hist(train_vectors.data, bins=20)\n",
        "plt.title('Распределение весов признаков')\n",
        "plt.yscale('log');"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD8OBFdAErFL",
        "outputId": "b4a6a5bc-5850-49d6-fc1b-8043c9f5f255"
      },
      "source": [
        "# del\n",
        "\n",
        "texts = [\n",
        "    'Казнить нельзя, помиловать. Нельзя наказывать.',\n",
        "    'Казнить, нельзя помиловать. Нельзя освободить.',\n",
        "    'Нельзя не помиловать.',\n",
        "    'Обязательно освободить.'\n",
        "]\n",
        "\n",
        "tokenized = tokenize_corpus(texts, min_token_size=1)\n",
        "\n",
        "word_df = [('нельзя', 0.75), ('помиловать', 0.75), ('казнить', 0.5),\n",
        " ('освободить', 0.5), ('наказывать', 0.25), ('не', 0.25), ('обязательно', 0.25)]\n",
        "\n",
        "answer = sorted(word_df, key=lambda x:(x[1],x[0]))\n",
        "\n",
        "answer_1 = []; \n",
        "answer_2 = [];\n",
        "\n",
        "for k, v in list(answer):\n",
        "    answer_1.append(k)\n",
        "    answer_2.append(str(v))\n",
        "\n",
        "# TF\n",
        "matrix = np.zeros((len(texts), len(answer_1)))\n",
        "for i, text in enumerate(tokenized):\n",
        "    for j, token in enumerate(answer_1):\n",
        "        if token in tokenized[i]:\n",
        "            matrix[i][j] += text.count(token)\n",
        "    matrix[i] /= len(text)\n",
        "\n",
        "# IDF\n",
        "size = len(texts)\n",
        "counter_tokens = np.zeros(len(answer_1))\n",
        "for i, token in enumerate(answer_1):\n",
        "    for text in tokenized:\n",
        "        if token in text:\n",
        "            counter_tokens[i] += text.count(token)\n",
        "counter_tokens = size / (counter_tokens + 1e-10)\n",
        "\n",
        "# ln(TF + 1) * IDF\n",
        "matrix = np.log(matrix + 1) * counter_tokens\n",
        "\n",
        "# Standartization\n",
        "feats_std = matrix.std(0, ddof=1)\n",
        "feats_mean = np.mean(matrix, axis=0)\n",
        "matrix = (matrix - feats_mean) / feats_std\n",
        "\n",
        "\n",
        "for row in matrix:\n",
        "    print(' '.join([str(i) for i in row]))"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5000000000000002 -0.5 -0.5 0.8660254037844386 -0.7630125578876947 0.5954669471484166 0.1609678767201035\n",
            "-0.5 -0.5 -0.5 0.8660254037844386 0.18368219185173845 0.5954669471484166 0.1609678767201035\n",
            "-0.5 1.5 -0.5 -0.8660254037844386 -0.7630125578876947 0.29382391061831536 1.0424350837750262\n",
            "-0.5 -0.5 1.5 -0.8660254037844386 1.3423429239236506 -1.4847578049151484 -1.3643708372152332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYZ7KEchuM3n"
      },
      "source": [
        "#### Распределение классов\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eQy-NpEuNHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d62ce8-7027-488c-9968-30812bb31ac4"
      },
      "source": [
        "UNIQUE_LABELS_N = len(set(train_data['target']))\n",
        "print('Количество уникальных меток', UNIQUE_LABELS_N)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество уникальных меток 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OiAu12vfOfGn",
        "outputId": "4ca776aa-50ff-4ec2-fd4b-9f0810af39fd"
      },
      "source": [
        "plt.hist(train_data['target'], bins=np.arange(0, 21))\n",
        "plt.title('Распределение меток в обучающей выборке');"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "gNIhVrdWOhKa",
        "outputId": "f3a8d851-e6e2-4f33-9600-ad48aea8e985"
      },
      "source": [
        "plt.hist(test_data['target'], bins=np.arange(0, 21))\n",
        "plt.title('Распределение меток в тестовой выборке');"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGOYhRo_uNTf"
      },
      "source": [
        "#### PyTorch Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HteNBe57uR9A"
      },
      "source": [
        "train_dataset = SparseFeaturesDataset(train_vectors, train_data['target'])\n",
        "test_dataset = SparseFeaturesDataset(test_vectors, test_data['target'])"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcV40rkuuTOB"
      },
      "source": [
        "### Обучение модели на PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIAEwwbDuUaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad329f89-bf3e-4a3f-a11e-3413acdbdab3"
      },
      "source": [
        "model = nn.Linear(UNIQUE_WORDS_N, UNIQUE_LABELS_N)\n",
        "\n",
        "scheduler = lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
        "batch_size = 32\n",
        "best_val_loss, best_model = train_eval_loop(model=model,\n",
        "                                            train_dataset=train_dataset,\n",
        "                                            val_dataset=test_dataset,\n",
        "                                            criterion=F.cross_entropy,\n",
        "                                            lr=1e-1,\n",
        "                                            epoch_n=200,\n",
        "                                            batch_size=batch_size,\n",
        "                                            l2_reg_alpha=0,\n",
        "                                            lr_scheduler_ctor=scheduler,\n",
        "                                            max_batches_per_epoch_train=len(train_dataset) // batch_size,\n",
        "                                            max_batches_per_epoch_val=len(test_dataset) // batch_size)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпоха 0\n",
            "Эпоха: 354 итераций, 1.81 сек\n",
            "Среднее значение функции потерь на обучении 1.107504807075875\n",
            "Среднее значение функции потерь на валидации 1.9285991661629434\n",
            "Новая лучшая модель!\n",
            "\n",
            "Эпоха 1\n",
            "Эпоха: 354 итераций, 1.74 сек\n",
            "Среднее значение функции потерь на обучении 0.09613363615444433\n",
            "Среднее значение функции потерь на валидации 2.061961509161076\n",
            "\n",
            "Эпоха 2\n",
            "Эпоха: 354 итераций, 1.72 сек\n",
            "Среднее значение функции потерь на обучении 0.044606514301136393\n",
            "Среднее значение функции потерь на валидации 2.0304274644892093\n",
            "\n",
            "Эпоха 3\n",
            "Эпоха: 354 итераций, 1.80 сек\n",
            "Среднее значение функции потерь на обучении 0.03698849842874609\n",
            "Среднее значение функции потерь на валидации 2.2358774301611772\n",
            "\n",
            "Эпоха 4\n",
            "Эпоха: 354 итераций, 1.77 сек\n",
            "Среднее значение функции потерь на обучении 0.04849758947361053\n",
            "Среднее значение функции потерь на валидации 2.067010013228756\n",
            "\n",
            "Эпоха 5\n",
            "Досрочно остановлено пользователем\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NhgovcUuVbH"
      },
      "source": [
        "### Оценка качества\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx189fSkuWY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5770dc-9584-4115-a21f-86faaa0039ef"
      },
      "source": [
        "train_predict = predict_with_model(best_model, train_dataset)\n",
        "train_loss = F.cross_entropy(torch.from_numpy(train_predict),\n",
        "                             torch.from_numpy(train_data['target']))\n",
        "\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print('Доля верных ответов', accuracy_score(train_data['target'], train_predict.argmax(axis=1)))\n",
        "print()\n",
        "\n",
        "test_predict = predict_with_model(best_model, test_dataset)\n",
        "test_loss = F.cross_entropy(torch.from_numpy(test_predict),\n",
        "                            torch.from_numpy(test_data['target']))\n",
        "\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print('Доля верных ответов', accuracy_score(test_data['target'], test_predict.argmax(axis=1)))"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 351/353.5625 [00:01<00:00, 225.31it/s]/usr/local/lib/python3.6/dist-packages/tqdm/std.py:484: TqdmWarning: clamping frac to range [0, 1]\n",
            "  charset=Bar.ASCII if ascii is True else ascii or Bar.UTF)\n",
            "100%|██████████| 354/353.5625 [00:01<00:00, 226.03it/s]\n",
            " 10%|▉         | 23/235.375 [00:00<00:00, 229.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на обучении 0.08887787908315659\n",
            "Доля верных ответов 0.9852395262506629\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "236it [00:01, 225.20it/s]                             "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на валидации 1.9238135814666748\n",
            "Доля верных ответов 0.7396441848114711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xesMHwu9uXfT"
      },
      "source": [
        "## Альтернативная реализация на scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izxnLcP5uYdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbae5625-f23d-413f-c9d3-a8d697b7a2c8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "model_sk = Pipeline((\n",
        "    ('vectorize', TfidfVectorizer(tokenizer=tokenize_text_simple_regex,\n",
        "                                            max_df=MAX_DF,\n",
        "                                            min_df=MIN_COUNT)),\n",
        "    ('clsf', LogisticRegression())\n",
        "))\n",
        "\n",
        "model_sk.fit(train_data['data'], train_data['target'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorize',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=0.8, max_features=None,\n",
              "                                 min_df=5, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patte...\n",
              "                                 tokenizer=<function tokenize_text_simple_regex at 0x7f053d3b4378>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clsf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvC2Ft-YuZ-h"
      },
      "source": [
        "### Оценка качества\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CRgEL0FuamX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abc9aea-3754-4ef6-a2bb-76d5bd0fe2d5"
      },
      "source": [
        "train_predict = model_sk.predict_proba(train_data['data'])\n",
        "train_loss = F.cross_entropy(torch.from_numpy(train_predict),\n",
        "                             torch.from_numpy(train_data['target']))\n",
        "\n",
        "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
        "print('Доля верных ответов', accuracy_score(train_data['target'], train_predict.argmax(axis=1)))\n",
        "print()\n",
        "\n",
        "test_predict = model_sk.predict_proba(test_data['data'])\n",
        "test_loss = F.cross_entropy(torch.from_numpy(test_predict),\n",
        "                            torch.from_numpy(test_data['target']))\n",
        "\n",
        "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
        "print('Доля верных ответов', accuracy_score(test_data['target'], test_predict.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Среднее значение функции потерь на обучении 2.495478891857855\n",
            "Доля верных ответов 0.9716280714159449\n",
            "\n",
            "Среднее значение функции потерь на валидации 2.653902258233705\n",
            "Доля верных ответов 0.8190387679235263\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}